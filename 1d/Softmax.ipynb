{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax\n",
    "\n",
    "Simple 1D softmax classifier model. Includes support for:\n",
    "\n",
    "- Training on minibatches of training examples at a time\n",
    "- Finite difference gradient checking\n",
    "- Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Model = namedtuple('Model', ['ws', 'bs', 'dws', 'dbs', 'loss'])\n",
    "State = namedtuple('State', ['loss', 'dws', 'dbs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(scores):\n",
    "    \"\"\"Compute the softmax between two numbers\n",
    "    \n",
    "    s1 is the number we're finding the softmax of\n",
    "    \n",
    "    \"\"\"\n",
    "    e_x = np.exp(scores)\n",
    "    \n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    \"\"\"Initialize model parameters\n",
    "    \n",
    "    Additionally calculate batch index so we can use minibatches with each training iteration\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, xs_train=1, ys_train=1, ws=None, bs=None, learning_rate=0.001, batch_size=None):\n",
    "        self.m = len(xs_train)\n",
    "        \n",
    "        self.xs_train, self.ys_train = xs_train, ys_train\n",
    "        self.ws, self.bs = np.array([50.,65.]), np.array([100.,150.])\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.batch_size = self.m if not batch_size else batch_size\n",
    "        self.batch_index = 0\n",
    "        \n",
    "    def forward_backward_prop(self, ws=None, bs=None):\n",
    "        \"\"\"Perform forward and backward prop over a minibatch of training examples\n",
    "        \n",
    "        Returns loss and gradients\n",
    "        \n",
    "        \"\"\"\n",
    "        ws = self.ws if not ws else ws\n",
    "        bs = self.bs if not bs else bs\n",
    "        \n",
    "        loss, dws, dbs = 0., np.array([0.,0.]), np.array([0.,0.])\n",
    "        lower, upper = self.batch_index*self.batch_size, (self.batch_index+1)*self.batch_size\n",
    "        for x, y in zip(self.xs_train[lower:upper], self.ys_train[lower:upper]):\n",
    "            # Forward propagation\n",
    "            scores = np.array([x,x])*ws + bs\n",
    "            probs = softmax(scores)\n",
    "\n",
    "            # Accumulate loss\n",
    "            loss += -np.log(probs[y])\n",
    "\n",
    "            # Backpropagate to accumulate dbs and dws\n",
    "            dloss = 1\n",
    "            dscores = probs\n",
    "            dscores[y] -= 1\n",
    "            dbs += dscores\n",
    "            dws += x * dscores\n",
    "        \n",
    "        return State(loss/self.m, dws/self.m, dbs/self.m)\n",
    "    \n",
    "    def step(self):\n",
    "        \"\"\"Run one iteration of gradient descent with a minibatch of training examples\"\"\"\n",
    "        \n",
    "        loss, dws, dbs = self.forward_backward_prop()\n",
    "        \n",
    "        self.ws = self.ws - self.learning_rate*dws\n",
    "        self.bs = self.bs - self.learning_rate*dbs\n",
    "        \n",
    "        # Update batch index so the next time the next batch in line is used\n",
    "        self.batch_index = (self.batch_index+1) % (self.m//self.batch_size)\n",
    "                \n",
    "        return Model(self.ws, self.bs, dws, dbs, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data.softmax import xs_train, ys_train\n",
    "\n",
    "sm = Softmax(xs_train, ys_train, learning_rate=0.01, batch_size=2)\n",
    "\n",
    "def estimates(iters):\n",
    "    for _ in range(iters):\n",
    "        yield sm.step()\n",
    "        \n",
    "estimates = list(estimates(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ws</th>\n",
       "      <th>bs</th>\n",
       "      <th>dws</th>\n",
       "      <th>dbs</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[49.995, 65.005]</td>\n",
       "      <td>[100.005, 149.995]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[49.99, 65.01]</td>\n",
       "      <td>[100.01, 149.99]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[49.985, 65.015]</td>\n",
       "      <td>[100.015, 149.985]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[49.98, 65.02]</td>\n",
       "      <td>[100.02, 149.98]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[49.975, 65.025]</td>\n",
       "      <td>[100.025, 149.975]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[49.97, 65.03]</td>\n",
       "      <td>[100.03, 149.97]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[49.965, 65.035]</td>\n",
       "      <td>[100.035, 149.965]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[49.96, 65.04]</td>\n",
       "      <td>[100.04, 149.96]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[49.955, 65.045]</td>\n",
       "      <td>[100.045, 149.955]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[49.95, 65.05]</td>\n",
       "      <td>[100.05, 149.95]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[49.945, 65.055]</td>\n",
       "      <td>[100.055, 149.945]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[49.94, 65.06]</td>\n",
       "      <td>[100.06, 149.94]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[49.935, 65.065]</td>\n",
       "      <td>[100.065, 149.935]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[49.93, 65.07]</td>\n",
       "      <td>[100.07, 149.93]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[49.925, 65.075]</td>\n",
       "      <td>[100.075, 149.925]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[49.92, 65.08]</td>\n",
       "      <td>[100.08, 149.92]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[49.915, 65.085]</td>\n",
       "      <td>[100.085, 149.915]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[49.91, 65.09]</td>\n",
       "      <td>[100.09, 149.91]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[49.905, 65.095]</td>\n",
       "      <td>[100.095, 149.905]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[49.9, 65.1]</td>\n",
       "      <td>[100.1, 149.9]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[49.895, 65.105]</td>\n",
       "      <td>[100.105, 149.895]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[49.89, 65.11]</td>\n",
       "      <td>[100.11, 149.89]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[49.885, 65.115]</td>\n",
       "      <td>[100.115, 149.885]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[49.88, 65.12]</td>\n",
       "      <td>[100.12, 149.88]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[49.875, 65.125]</td>\n",
       "      <td>[100.125, 149.875]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[49.87, 65.13]</td>\n",
       "      <td>[100.13, 149.87]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[49.865, 65.135]</td>\n",
       "      <td>[100.135, 149.865]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[49.86, 65.14]</td>\n",
       "      <td>[100.14, 149.86]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[49.855, 65.145]</td>\n",
       "      <td>[100.145, 149.855]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[49.85, 65.15]</td>\n",
       "      <td>[100.15, 149.85]</td>\n",
       "      <td>[0.5, -0.5]</td>\n",
       "      <td>[-0.5, 0.5]</td>\n",
       "      <td>17.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49970</th>\n",
       "      <td>[39.5338861394, 75.4661138606]</td>\n",
       "      <td>[110.466113861, 139.533886139]</td>\n",
       "      <td>[0.000521591685901, -0.000521591685901]</td>\n",
       "      <td>[-0.000521591685901, 0.000521591685901]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49971</th>\n",
       "      <td>[39.5338809236, 75.4661190764]</td>\n",
       "      <td>[110.466119076, 139.533880924]</td>\n",
       "      <td>[0.000521580815051, -0.00052158081505]</td>\n",
       "      <td>[-0.000521580815051, 0.00052158081505]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49972</th>\n",
       "      <td>[39.5338757079, 75.4661242921]</td>\n",
       "      <td>[110.466124292, 139.533875708]</td>\n",
       "      <td>[0.000521569944653, -0.000521569944653]</td>\n",
       "      <td>[-0.000521569944653, 0.000521569944653]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49973</th>\n",
       "      <td>[39.5338704923, 75.4661295077]</td>\n",
       "      <td>[110.466129508, 139.533870492]</td>\n",
       "      <td>[0.000521559074709, -0.000521559074709]</td>\n",
       "      <td>[-0.000521559074709, 0.000521559074709]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49974</th>\n",
       "      <td>[39.5338652768, 75.4661347232]</td>\n",
       "      <td>[110.466134723, 139.533865277]</td>\n",
       "      <td>[0.000521548205218, -0.000521548205218]</td>\n",
       "      <td>[-0.000521548205218, 0.000521548205218]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49975</th>\n",
       "      <td>[39.5338600615, 75.4661399385]</td>\n",
       "      <td>[110.466139939, 139.533860061]</td>\n",
       "      <td>[0.000521537336179, -0.000521537336179]</td>\n",
       "      <td>[-0.000521537336179, 0.000521537336179]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49976</th>\n",
       "      <td>[39.5338548462, 75.4661451538]</td>\n",
       "      <td>[110.466145154, 139.533854846]</td>\n",
       "      <td>[0.000521526467593, -0.000521526467593]</td>\n",
       "      <td>[-0.000521526467593, 0.000521526467593]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49977</th>\n",
       "      <td>[39.533849631, 75.466150369]</td>\n",
       "      <td>[110.466150369, 139.533849631]</td>\n",
       "      <td>[0.00052151559946, -0.00052151559946]</td>\n",
       "      <td>[-0.00052151559946, 0.00052151559946]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49978</th>\n",
       "      <td>[39.533844416, 75.466155584]</td>\n",
       "      <td>[110.466155584, 139.533844416]</td>\n",
       "      <td>[0.000521504731779, -0.000521504731779]</td>\n",
       "      <td>[-0.000521504731779, 0.000521504731779]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49979</th>\n",
       "      <td>[39.5338392011, 75.4661607989]</td>\n",
       "      <td>[110.466160799, 139.533839201]</td>\n",
       "      <td>[0.000521493864552, -0.000521493864552]</td>\n",
       "      <td>[-0.000521493864552, 0.000521493864552]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49980</th>\n",
       "      <td>[39.5338339862, 75.4661660138]</td>\n",
       "      <td>[110.466166014, 139.533833986]</td>\n",
       "      <td>[0.000521482997777, -0.000521482997777]</td>\n",
       "      <td>[-0.000521482997777, 0.000521482997777]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49981</th>\n",
       "      <td>[39.5338287715, 75.4661712285]</td>\n",
       "      <td>[110.466171228, 139.533828772]</td>\n",
       "      <td>[0.000521472131454, -0.000521472131454]</td>\n",
       "      <td>[-0.000521472131454, 0.000521472131454]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49982</th>\n",
       "      <td>[39.5338235569, 75.4661764431]</td>\n",
       "      <td>[110.466176443, 139.533823557]</td>\n",
       "      <td>[0.000521461265584, -0.000521461265584]</td>\n",
       "      <td>[-0.000521461265584, 0.000521461265584]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49983</th>\n",
       "      <td>[39.5338183424, 75.4661816576]</td>\n",
       "      <td>[110.466181658, 139.533818342]</td>\n",
       "      <td>[0.000521450400167, -0.000521450400167]</td>\n",
       "      <td>[-0.000521450400167, 0.000521450400167]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49984</th>\n",
       "      <td>[39.533813128, 75.466186872]</td>\n",
       "      <td>[110.466186872, 139.533813128]</td>\n",
       "      <td>[0.000521439535202, -0.000521439535202]</td>\n",
       "      <td>[-0.000521439535202, 0.000521439535202]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49985</th>\n",
       "      <td>[39.5338079137, 75.4661920863]</td>\n",
       "      <td>[110.466192086, 139.533807914]</td>\n",
       "      <td>[0.00052142867069, -0.00052142867069]</td>\n",
       "      <td>[-0.00052142867069, 0.00052142867069]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49986</th>\n",
       "      <td>[39.5338026995, 75.4661973005]</td>\n",
       "      <td>[110.4661973, 139.5338027]</td>\n",
       "      <td>[0.000521417806631, -0.000521417806631]</td>\n",
       "      <td>[-0.000521417806631, 0.000521417806631]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49987</th>\n",
       "      <td>[39.5337974855, 75.4662025145]</td>\n",
       "      <td>[110.466202515, 139.533797485]</td>\n",
       "      <td>[0.000521406943023, -0.000521406943023]</td>\n",
       "      <td>[-0.000521406943023, 0.000521406943023]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49988</th>\n",
       "      <td>[39.5337922715, 75.4662077285]</td>\n",
       "      <td>[110.466207728, 139.533792271]</td>\n",
       "      <td>[0.000521396079869, -0.000521396079869]</td>\n",
       "      <td>[-0.000521396079869, 0.000521396079869]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49989</th>\n",
       "      <td>[39.5337870576, 75.4662129424]</td>\n",
       "      <td>[110.466212942, 139.533787058]</td>\n",
       "      <td>[0.000521385217166, -0.000521385217166]</td>\n",
       "      <td>[-0.000521385217166, 0.000521385217166]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49990</th>\n",
       "      <td>[39.5337818439, 75.4662181561]</td>\n",
       "      <td>[110.466218156, 139.533781844]</td>\n",
       "      <td>[0.000521374354916, -0.000521374354916]</td>\n",
       "      <td>[-0.000521374354916, 0.000521374354916]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49991</th>\n",
       "      <td>[39.5337766303, 75.4662233697]</td>\n",
       "      <td>[110.46622337, 139.53377663]</td>\n",
       "      <td>[0.000521363493119, -0.000521363493119]</td>\n",
       "      <td>[-0.000521363493119, 0.000521363493119]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49992</th>\n",
       "      <td>[39.5337714167, 75.4662285833]</td>\n",
       "      <td>[110.466228583, 139.533771417]</td>\n",
       "      <td>[0.000521352631773, -0.000521352631773]</td>\n",
       "      <td>[-0.000521352631773, 0.000521352631773]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49993</th>\n",
       "      <td>[39.5337662033, 75.4662337967]</td>\n",
       "      <td>[110.466233797, 139.533766203]</td>\n",
       "      <td>[0.00052134177088, -0.00052134177088]</td>\n",
       "      <td>[-0.00052134177088, 0.00052134177088]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49994</th>\n",
       "      <td>[39.53376099, 75.46623901]</td>\n",
       "      <td>[110.46623901, 139.53376099]</td>\n",
       "      <td>[0.00052133091044, -0.00052133091044]</td>\n",
       "      <td>[-0.00052133091044, 0.00052133091044]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>[39.5337557768, 75.4662442232]</td>\n",
       "      <td>[110.466244223, 139.533755777]</td>\n",
       "      <td>[0.000521320050451, -0.000521320050451]</td>\n",
       "      <td>[-0.000521320050451, 0.000521320050451]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>[39.5337505637, 75.4662494363]</td>\n",
       "      <td>[110.466249436, 139.533750564]</td>\n",
       "      <td>[0.000521309190915, -0.000521309190915]</td>\n",
       "      <td>[-0.000521309190915, 0.000521309190915]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>[39.5337453507, 75.4662546493]</td>\n",
       "      <td>[110.466254649, 139.533745351]</td>\n",
       "      <td>[0.000521298331831, -0.000521298331831]</td>\n",
       "      <td>[-0.000521298331831, 0.000521298331831]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>[39.5337401379, 75.4662598621]</td>\n",
       "      <td>[110.466259862, 139.533740138]</td>\n",
       "      <td>[0.000521287473199, -0.000521287473199]</td>\n",
       "      <td>[-0.000521287473199, 0.000521287473199]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>[39.5337349251, 75.4662650749]</td>\n",
       "      <td>[110.466265075, 139.533734925]</td>\n",
       "      <td>[0.000521276615019, -0.000521276615019]</td>\n",
       "      <td>[-0.000521276615019, 0.000521276615019]</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   ws                              bs  \\\n",
       "0                    [49.995, 65.005]              [100.005, 149.995]   \n",
       "1                      [49.99, 65.01]                [100.01, 149.99]   \n",
       "2                    [49.985, 65.015]              [100.015, 149.985]   \n",
       "3                      [49.98, 65.02]                [100.02, 149.98]   \n",
       "4                    [49.975, 65.025]              [100.025, 149.975]   \n",
       "5                      [49.97, 65.03]                [100.03, 149.97]   \n",
       "6                    [49.965, 65.035]              [100.035, 149.965]   \n",
       "7                      [49.96, 65.04]                [100.04, 149.96]   \n",
       "8                    [49.955, 65.045]              [100.045, 149.955]   \n",
       "9                      [49.95, 65.05]                [100.05, 149.95]   \n",
       "10                   [49.945, 65.055]              [100.055, 149.945]   \n",
       "11                     [49.94, 65.06]                [100.06, 149.94]   \n",
       "12                   [49.935, 65.065]              [100.065, 149.935]   \n",
       "13                     [49.93, 65.07]                [100.07, 149.93]   \n",
       "14                   [49.925, 65.075]              [100.075, 149.925]   \n",
       "15                     [49.92, 65.08]                [100.08, 149.92]   \n",
       "16                   [49.915, 65.085]              [100.085, 149.915]   \n",
       "17                     [49.91, 65.09]                [100.09, 149.91]   \n",
       "18                   [49.905, 65.095]              [100.095, 149.905]   \n",
       "19                       [49.9, 65.1]                  [100.1, 149.9]   \n",
       "20                   [49.895, 65.105]              [100.105, 149.895]   \n",
       "21                     [49.89, 65.11]                [100.11, 149.89]   \n",
       "22                   [49.885, 65.115]              [100.115, 149.885]   \n",
       "23                     [49.88, 65.12]                [100.12, 149.88]   \n",
       "24                   [49.875, 65.125]              [100.125, 149.875]   \n",
       "25                     [49.87, 65.13]                [100.13, 149.87]   \n",
       "26                   [49.865, 65.135]              [100.135, 149.865]   \n",
       "27                     [49.86, 65.14]                [100.14, 149.86]   \n",
       "28                   [49.855, 65.145]              [100.145, 149.855]   \n",
       "29                     [49.85, 65.15]                [100.15, 149.85]   \n",
       "...                               ...                             ...   \n",
       "49970  [39.5338861394, 75.4661138606]  [110.466113861, 139.533886139]   \n",
       "49971  [39.5338809236, 75.4661190764]  [110.466119076, 139.533880924]   \n",
       "49972  [39.5338757079, 75.4661242921]  [110.466124292, 139.533875708]   \n",
       "49973  [39.5338704923, 75.4661295077]  [110.466129508, 139.533870492]   \n",
       "49974  [39.5338652768, 75.4661347232]  [110.466134723, 139.533865277]   \n",
       "49975  [39.5338600615, 75.4661399385]  [110.466139939, 139.533860061]   \n",
       "49976  [39.5338548462, 75.4661451538]  [110.466145154, 139.533854846]   \n",
       "49977    [39.533849631, 75.466150369]  [110.466150369, 139.533849631]   \n",
       "49978    [39.533844416, 75.466155584]  [110.466155584, 139.533844416]   \n",
       "49979  [39.5338392011, 75.4661607989]  [110.466160799, 139.533839201]   \n",
       "49980  [39.5338339862, 75.4661660138]  [110.466166014, 139.533833986]   \n",
       "49981  [39.5338287715, 75.4661712285]  [110.466171228, 139.533828772]   \n",
       "49982  [39.5338235569, 75.4661764431]  [110.466176443, 139.533823557]   \n",
       "49983  [39.5338183424, 75.4661816576]  [110.466181658, 139.533818342]   \n",
       "49984    [39.533813128, 75.466186872]  [110.466186872, 139.533813128]   \n",
       "49985  [39.5338079137, 75.4661920863]  [110.466192086, 139.533807914]   \n",
       "49986  [39.5338026995, 75.4661973005]      [110.4661973, 139.5338027]   \n",
       "49987  [39.5337974855, 75.4662025145]  [110.466202515, 139.533797485]   \n",
       "49988  [39.5337922715, 75.4662077285]  [110.466207728, 139.533792271]   \n",
       "49989  [39.5337870576, 75.4662129424]  [110.466212942, 139.533787058]   \n",
       "49990  [39.5337818439, 75.4662181561]  [110.466218156, 139.533781844]   \n",
       "49991  [39.5337766303, 75.4662233697]    [110.46622337, 139.53377663]   \n",
       "49992  [39.5337714167, 75.4662285833]  [110.466228583, 139.533771417]   \n",
       "49993  [39.5337662033, 75.4662337967]  [110.466233797, 139.533766203]   \n",
       "49994      [39.53376099, 75.46623901]    [110.46623901, 139.53376099]   \n",
       "49995  [39.5337557768, 75.4662442232]  [110.466244223, 139.533755777]   \n",
       "49996  [39.5337505637, 75.4662494363]  [110.466249436, 139.533750564]   \n",
       "49997  [39.5337453507, 75.4662546493]  [110.466254649, 139.533745351]   \n",
       "49998  [39.5337401379, 75.4662598621]  [110.466259862, 139.533740138]   \n",
       "49999  [39.5337349251, 75.4662650749]  [110.466265075, 139.533734925]   \n",
       "\n",
       "                                           dws  \\\n",
       "0                                  [0.5, -0.5]   \n",
       "1                                  [0.5, -0.5]   \n",
       "2                                  [0.5, -0.5]   \n",
       "3                                  [0.5, -0.5]   \n",
       "4                                  [0.5, -0.5]   \n",
       "5                                  [0.5, -0.5]   \n",
       "6                                  [0.5, -0.5]   \n",
       "7                                  [0.5, -0.5]   \n",
       "8                                  [0.5, -0.5]   \n",
       "9                                  [0.5, -0.5]   \n",
       "10                                 [0.5, -0.5]   \n",
       "11                                 [0.5, -0.5]   \n",
       "12                                 [0.5, -0.5]   \n",
       "13                                 [0.5, -0.5]   \n",
       "14                                 [0.5, -0.5]   \n",
       "15                                 [0.5, -0.5]   \n",
       "16                                 [0.5, -0.5]   \n",
       "17                                 [0.5, -0.5]   \n",
       "18                                 [0.5, -0.5]   \n",
       "19                                 [0.5, -0.5]   \n",
       "20                                 [0.5, -0.5]   \n",
       "21                                 [0.5, -0.5]   \n",
       "22                                 [0.5, -0.5]   \n",
       "23                                 [0.5, -0.5]   \n",
       "24                                 [0.5, -0.5]   \n",
       "25                                 [0.5, -0.5]   \n",
       "26                                 [0.5, -0.5]   \n",
       "27                                 [0.5, -0.5]   \n",
       "28                                 [0.5, -0.5]   \n",
       "29                                 [0.5, -0.5]   \n",
       "...                                        ...   \n",
       "49970  [0.000521591685901, -0.000521591685901]   \n",
       "49971   [0.000521580815051, -0.00052158081505]   \n",
       "49972  [0.000521569944653, -0.000521569944653]   \n",
       "49973  [0.000521559074709, -0.000521559074709]   \n",
       "49974  [0.000521548205218, -0.000521548205218]   \n",
       "49975  [0.000521537336179, -0.000521537336179]   \n",
       "49976  [0.000521526467593, -0.000521526467593]   \n",
       "49977    [0.00052151559946, -0.00052151559946]   \n",
       "49978  [0.000521504731779, -0.000521504731779]   \n",
       "49979  [0.000521493864552, -0.000521493864552]   \n",
       "49980  [0.000521482997777, -0.000521482997777]   \n",
       "49981  [0.000521472131454, -0.000521472131454]   \n",
       "49982  [0.000521461265584, -0.000521461265584]   \n",
       "49983  [0.000521450400167, -0.000521450400167]   \n",
       "49984  [0.000521439535202, -0.000521439535202]   \n",
       "49985    [0.00052142867069, -0.00052142867069]   \n",
       "49986  [0.000521417806631, -0.000521417806631]   \n",
       "49987  [0.000521406943023, -0.000521406943023]   \n",
       "49988  [0.000521396079869, -0.000521396079869]   \n",
       "49989  [0.000521385217166, -0.000521385217166]   \n",
       "49990  [0.000521374354916, -0.000521374354916]   \n",
       "49991  [0.000521363493119, -0.000521363493119]   \n",
       "49992  [0.000521352631773, -0.000521352631773]   \n",
       "49993    [0.00052134177088, -0.00052134177088]   \n",
       "49994    [0.00052133091044, -0.00052133091044]   \n",
       "49995  [0.000521320050451, -0.000521320050451]   \n",
       "49996  [0.000521309190915, -0.000521309190915]   \n",
       "49997  [0.000521298331831, -0.000521298331831]   \n",
       "49998  [0.000521287473199, -0.000521287473199]   \n",
       "49999  [0.000521276615019, -0.000521276615019]   \n",
       "\n",
       "                                           dbs       loss  \n",
       "0                                  [-0.5, 0.5]  17.500000  \n",
       "1                                  [-0.5, 0.5]  17.490000  \n",
       "2                                  [-0.5, 0.5]  17.480000  \n",
       "3                                  [-0.5, 0.5]  17.470000  \n",
       "4                                  [-0.5, 0.5]  17.460000  \n",
       "5                                  [-0.5, 0.5]  17.450000  \n",
       "6                                  [-0.5, 0.5]  17.440000  \n",
       "7                                  [-0.5, 0.5]  17.430000  \n",
       "8                                  [-0.5, 0.5]  17.420000  \n",
       "9                                  [-0.5, 0.5]  17.410000  \n",
       "10                                 [-0.5, 0.5]  17.400000  \n",
       "11                                 [-0.5, 0.5]  17.390000  \n",
       "12                                 [-0.5, 0.5]  17.380000  \n",
       "13                                 [-0.5, 0.5]  17.370000  \n",
       "14                                 [-0.5, 0.5]  17.360000  \n",
       "15                                 [-0.5, 0.5]  17.350000  \n",
       "16                                 [-0.5, 0.5]  17.340000  \n",
       "17                                 [-0.5, 0.5]  17.330000  \n",
       "18                                 [-0.5, 0.5]  17.320000  \n",
       "19                                 [-0.5, 0.5]  17.310000  \n",
       "20                                 [-0.5, 0.5]  17.300000  \n",
       "21                                 [-0.5, 0.5]  17.290000  \n",
       "22                                 [-0.5, 0.5]  17.280000  \n",
       "23                                 [-0.5, 0.5]  17.270000  \n",
       "24                                 [-0.5, 0.5]  17.260000  \n",
       "25                                 [-0.5, 0.5]  17.250000  \n",
       "26                                 [-0.5, 0.5]  17.240000  \n",
       "27                                 [-0.5, 0.5]  17.230000  \n",
       "28                                 [-0.5, 0.5]  17.220000  \n",
       "29                                 [-0.5, 0.5]  17.210000  \n",
       "...                                        ...        ...  \n",
       "49970  [-0.000521591685901, 0.000521591685901]   0.000522  \n",
       "49971   [-0.000521580815051, 0.00052158081505]   0.000522  \n",
       "49972  [-0.000521569944653, 0.000521569944653]   0.000522  \n",
       "49973  [-0.000521559074709, 0.000521559074709]   0.000522  \n",
       "49974  [-0.000521548205218, 0.000521548205218]   0.000522  \n",
       "49975  [-0.000521537336179, 0.000521537336179]   0.000522  \n",
       "49976  [-0.000521526467593, 0.000521526467593]   0.000522  \n",
       "49977    [-0.00052151559946, 0.00052151559946]   0.000522  \n",
       "49978  [-0.000521504731779, 0.000521504731779]   0.000522  \n",
       "49979  [-0.000521493864552, 0.000521493864552]   0.000522  \n",
       "49980  [-0.000521482997777, 0.000521482997777]   0.000522  \n",
       "49981  [-0.000521472131454, 0.000521472131454]   0.000522  \n",
       "49982  [-0.000521461265584, 0.000521461265584]   0.000522  \n",
       "49983  [-0.000521450400167, 0.000521450400167]   0.000522  \n",
       "49984  [-0.000521439535202, 0.000521439535202]   0.000522  \n",
       "49985    [-0.00052142867069, 0.00052142867069]   0.000522  \n",
       "49986  [-0.000521417806631, 0.000521417806631]   0.000522  \n",
       "49987  [-0.000521406943023, 0.000521406943023]   0.000522  \n",
       "49988  [-0.000521396079869, 0.000521396079869]   0.000522  \n",
       "49989  [-0.000521385217166, 0.000521385217166]   0.000522  \n",
       "49990  [-0.000521374354916, 0.000521374354916]   0.000522  \n",
       "49991  [-0.000521363493119, 0.000521363493119]   0.000522  \n",
       "49992  [-0.000521352631773, 0.000521352631773]   0.000522  \n",
       "49993    [-0.00052134177088, 0.00052134177088]   0.000522  \n",
       "49994    [-0.00052133091044, 0.00052133091044]   0.000522  \n",
       "49995  [-0.000521320050451, 0.000521320050451]   0.000522  \n",
       "49996  [-0.000521309190915, 0.000521309190915]   0.000522  \n",
       "49997  [-0.000521298331831, 0.000521298331831]   0.000522  \n",
       "49998  [-0.000521287473199, 0.000521287473199]   0.000522  \n",
       "49999  [-0.000521276615019, 0.000521276615019]   0.000522  \n",
       "\n",
       "[50000 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(estimates, columns=Model._fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Does the Model Evolve Over Time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEPCAYAAABY9lNGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZEBIkpoMCElS0/8DUCpIMA9Ot1kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f27b9abfe48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, fixed\n",
    "\n",
    "@interact(xs_train=fixed(xs_train), ys_train=fixed(ys_train), view_index=(0, len(estimates)), estimates=fixed(estimates))\n",
    "def plot(xs_train, ys_train, view_index, estimates):\n",
    "    ws, bs, _, _, _ = estimates[view_index]\n",
    "    \n",
    "    # Get data into suitable form for plotting\n",
    "    positives, negatives = xs_train[:len(xs_train)//2], xs_train[len(xs_train)//2:]\n",
    "    df1 = pd.DataFrame({'positives': positives, 'negatives': negatives, 'zeros': np.zeros_like(positives)})\n",
    "    \n",
    "    # Solve for the decision boundary\n",
    "    decision = (bs[1]-bs[0]) / (ws[0]-ws[1])\n",
    "    \n",
    "    ys = np.linspace(-.001,.001)\n",
    "    df2 = pd.DataFrame({'x': [decision], 'y': [0]})\n",
    "    \n",
    "    axes = df2.plot(kind='scatter', x='x', y='y', color='g', marker='|', s=10000)\n",
    "    axes = df1.plot(ax=axes, kind='scatter', x='positives', y='zeros', color='r', marker='+')\n",
    "    df1.plot(ax=axes, kind='scatter', x='negatives', y='zeros', color='b', marker='+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite Difference Gradient Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numerical_gradients(f, w, b):\n",
    "    \"\"\"Compute numerical gradients of f with respect to w and b\n",
    "    \n",
    "    Returns approximation for df/dw and df/db\n",
    "    \n",
    "    \"\"\"\n",
    "    h = 0.00001\n",
    "    \n",
    "    dw = (f(w+h, b)-f(w-h, b)) / (2*h)\n",
    "    db = (f(w, b+h)-f(w, b-h)) / (2*h)\n",
    "    \n",
    "    return dw, db "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Through a Few Iterations and Assert Analytic and Numerical Gradients are Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(xs_train, ys_train)\n",
    "\n",
    "for _ in range(10):\n",
    "    # Analytic gradient computed via backprop\n",
    "    _, analytic_dw, analytic_db = lr.forward_backward_prop()\n",
    "    \n",
    "    # Numerical gradient compute via twiddling w and b and inspecting loss\n",
    "    numerical_dw, numerical_db = numerical_gradients(lambda w, b: lr.forward_backward_prop(w, b).loss, lr.w, lr.b)\n",
    "    \n",
    "    # Compute relative error\n",
    "    dw_error = abs(numerical_dw - analytic_dw) / (abs(numerical_dw) + abs(analytic_dw))\n",
    "    db_error = abs(numerical_db - analytic_db) / (abs(numerical_db) + abs(analytic_db))\n",
    "    \n",
    "    try:\n",
    "        assert(dw_error < 1e-6 and db_error < 1e-6)\n",
    "    except AssertionError:\n",
    "        warn(dw_error)\n",
    "        warn(db_error)\n",
    "        \n",
    "else:\n",
    "    print('Gradient check passed!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
